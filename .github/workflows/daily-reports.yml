name: CommonSKU Daily Reports

on:
  # Scheduled run - 5 PM EST (22:00 UTC) on weekdays
  schedule:
    - cron: '0 22 * * 1-5'  # Mon-Fri at 5 PM EST (10 PM UTC)

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      report_type:
        description: 'Report type to run'
        required: true
        default: 'scheduled'
        type: choice
        options:
          - scheduled
          - daily
          - weekly
          - monthly
          - friday
          - all

jobs:
  run-reports:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Setup rclone
        run: |
          curl -O https://downloads.rclone.org/rclone-current-linux-amd64.zip
          unzip rclone-current-linux-amd64.zip
          sudo cp rclone-*-linux-amd64/rclone /usr/local/bin/
          sudo chmod +x /usr/local/bin/rclone
          rclone version

      - name: Configure rclone for Google Drive
        run: |
          mkdir -p ~/.config/rclone
          echo '${{ secrets.RCLONE_CONFIG }}' | base64 -d > ~/.config/rclone/rclone.conf

      - name: Create .env file
        env:
          COMMONSKU_URL: ${{ secrets.COMMONSKU_URL }}
          COMMONSKU_USERNAME: ${{ secrets.COMMONSKU_USERNAME }}
          COMMONSKU_PASSWORD: ${{ secrets.COMMONSKU_PASSWORD }}
        run: |
          cat > .env << ENVFILE
          COMMONSKU_URL=${COMMONSKU_URL}
          COMMONSKU_USERNAME=${COMMONSKU_USERNAME}
          COMMONSKU_PASSWORD=${COMMONSKU_PASSWORD}
          HEADLESS=true
          DOWNLOAD_DIR=./downloads
          NAVIGATION_TIMEOUT=60000
          ACTION_TIMEOUT=30000
          MAX_RETRIES=3
          RETRY_DELAY=5000
          DEBUG=true
          GDRIVE_ENABLED=true
          GDRIVE_UPLOAD_AFTER_EACH=true
          ENVFILE
          sed -i 's/^[[:space:]]*//' .env
          echo "--- .env file created ---"
          cat .env | grep -v PASSWORD

      - name: Create downloads directory
        run: mkdir -p downloads

      - name: Verify rclone config
        run: |
          echo "Checking rclone remotes..."
          rclone listremotes
          echo "Testing Google Drive access..."
          rclone lsd gdrive: --max-depth 1 || echo "Could not list Drive root"

      - name: Build TypeScript
        run: npm run build

      - name: Run reports (scheduled)
        if: github.event_name == 'schedule' || github.event.inputs.report_type == 'scheduled'
        run: node dist/index.js scheduled
        env:
          NODE_ENV: production

      - name: Run reports (manual)
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.report_type != 'scheduled'
        run: node dist/index.js ${{ github.event.inputs.report_type }}
        env:
          NODE_ENV: production

      - name: Upload to Google Drive
        if: always()
        run: |
          echo "=== Uploading reports to Google Drive ==="

          CURRENT_FOLDER="1opWJ_3RsH65sQ8GYWhMkpB5jL9WaKyRM"
          PREVIOUS_FOLDER="1EZdpKoVMCFBKbEfGMyxly3iZlrTjmcrm"

          upload_file() {
            local file="$1"
            local folder_id="$2"
            local folder_name="$3"
            local filename=$(basename "$file")
            echo "  -> $filename to $folder_name"
            rclone copy "$file" "gdrive:" --drive-root-folder-id "$folder_id" -v
          }

          echo ""
          echo "=== CURRENT DATA (Today, This Week, This Month, YTD) ==="

          # Root level daily files -> Current
          for file in downloads/*.csv; do
            [ -f "$file" ] && upload_file "$file" "$CURRENT_FOLDER" "Current Data"
          done

          # current-week folder -> Current
          if [ -d "downloads/current-week" ]; then
            for file in downloads/current-week/*.csv; do
              [ -f "$file" ] && upload_file "$file" "$CURRENT_FOLDER" "Current Data"
            done
          fi

          # current-month folder -> Current
          if [ -d "downloads/current-month" ]; then
            for file in downloads/current-month/*.csv; do
              [ -f "$file" ] && upload_file "$file" "$CURRENT_FOLDER" "Current Data"
            done
          fi

          # ytd folder -> Current
          if [ -d "downloads/ytd" ]; then
            for file in downloads/ytd/*.csv; do
              [ -f "$file" ] && upload_file "$file" "$CURRENT_FOLDER" "Current Data"
            done
          fi

          echo ""
          echo "=== PREVIOUS DATA (Last Week, Last Month) ==="

          # previous-week folder -> Previous
          if [ -d "downloads/previous-week" ]; then
            for file in downloads/previous-week/*.csv; do
              [ -f "$file" ] && upload_file "$file" "$PREVIOUS_FOLDER" "Previous Data"
            done
          fi

          # previous-month folder -> Previous
          if [ -d "downloads/previous-month" ]; then
            for file in downloads/previous-month/*.csv; do
              [ -f "$file" ] && upload_file "$file" "$PREVIOUS_FOLDER" "Previous Data"
            done
          fi

          echo ""
          echo "=== Upload complete ==="

      - name: Upload logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.run_id }}
          path: logs/
          retention-days: 7

      - name: Upload downloaded reports as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reports-${{ github.run_id }}
          path: downloads/
          retention-days: 7
